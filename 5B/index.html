<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>CS 180 Project 5 Part B: Flow Matching from Scratch!</title>
  <link href="https://fonts.googleapis.com/css2?family=Lato:wght@400;700&display=swap" rel="stylesheet">

  <style>
    body {
      font-family: 'Lato', sans-serif;
      text-align: center;
      margin: 0;
      padding: 0;
      background-color: #f9f9f9;
      color: #333;
    }

    .back-link {
      position: absolute;
      top: 20px;
      left: 20px;
      padding: 10px 18px;
      font-size: 1em;
      font-weight: 600;
      background-color: #eee;
      border-radius: 6px;
      text-decoration: none;
      color: #333;
      box-shadow: 0 2px 6px rgba(0,0,0,0.15);
      transition: background 0.2s ease, color 0.2s ease;
    }

    .back-link:hover {
      background-color: #ddd;
      color: #000;
    }

    h1 {
      font-size: 3em;
      margin: 60px 0 40px;
      font-weight: 700;
      color: #222;
    }

    .section {
      margin: 10px auto;
      padding: 10px 5px;
      width: 90%;
      background: #fff;
      border-radius: 12px;
      box-shadow: 0 4px 12px rgba(0,0,0,0.1);
    }

    .section h3 {
      margin-bottom: 20px;
      font-size: 1.8em;
      font-weight: 600;
      color: #111;
    }

    .images {
      display: flex;
      justify-content: center;
      align-items: center;
      gap: 40px;
      margin-bottom: 20px;
    }

    img {
      max-width: 600px;
      max-height: 500px;
      border-radius: 10px;
      flex-shrink: 0;
      box-shadow: 0 3px 10px rgba(0,0,0,0.15);
      transition: transform 0.2s ease;
    }

    img:hover {
      transform: scale(1.05);
    }

    .description {
      font-size: 1.1em;
      line-height: 1.7;
      max-width: 1200px;
      margin: 30px auto;
      color: #555;
    }

    .big-img {
      max-width: 90%;
      height: auto;
      margin-top: 10px;
      margin-bottom: 10px;
    }
  </style>
</head>
<body>
  <a href="https://eldenyap48.github.io/" class="back-link">← Back</a>

  <h1>CS 180 Project 5 Part B: Flow Matching from Scratch!</h1>

  <div class="section">
    <h3>Part 1.1: Implementing a Single-Step Denoising UNet</h3>
    <div class="description">
      We implement the denoiser as a compact U-Net with an encoder-decoder architecture and skip connections. The encoder consists of a convolutional block followed by two downsampling blocks that reduce the input from 28x28 to a 7x7 bottleneck, which is flattened to a 1x1 latent representation and then unflattened back to 7x7. The decoder mirrors the encoder using upsampling blocks and channel-wise concatenation with corresponding encoder features to preserve spatial detail, and a final 3x3 convolution maps the features back to the original image shape.
    </div>
  </div>

  <div class="section">
    <h3>Part 1.2: Using the UNet to Train a Denoiser</h3>
    <div class="description">
      We train the UNet as a denoiser by minimizing an L2 loss that encourages the network to map a noisy image z back to its clean target x. For each training batch, we generate supervision pairs (z, x) by sampling Gaussian noise ε ~ N(0, I) and forming z = x + sigma ε for different noise levels sigma. As sigma increases from 0 to 1, the input becomes progressively noisier and the digit structure becomes harder to distinguish, which we verify by visualizing examples across the specified sigma values.
    </div>
    <div class="images">
      <img src="media/increasing_sigmas.png" class="big-img">
    </div>
  </div>

  <div class="section">
    <h3>Part 1.2.1: Training</h3>
    <div class="description">
      We train the UNet denoiser on MNIST by adding Gaussian noise with a fixed noise level sigma = 0.5 to clean images and optimizing an L2 loss between the denoised output and the original image. During training, noise is applied on-the-fly each time a batch is fetched so the model sees different noisy realizations across epochs, improving generalization. We use the MNIST training set with shuffled batches, train for five epochs using the Adam optimizer, and monitor convergence by plotting the training loss over iterations. We report the training loss curve and visualize denoised results on the test set after the first and fifth epochs, comparing the clean input, noisy input, and the model's output.
    </div>
    <div class="images">
      <img src="media/training_loss_one_step.png" class="big-img">
    </div>
    <div class="images">
      <img src="media/one_step_epoch1.png" class="big-img">
    </div>
    <div class="images">
      <img src="media/one_step_epoch5.png" class="big-img">
    </div>
  </div>

</body>
</html>
