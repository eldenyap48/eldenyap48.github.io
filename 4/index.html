<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>CS 180 Project 4: Neural Radiance Field!</title>
  <link href="https://fonts.googleapis.com/css2?family=Lato:wght@400;700&display=swap" rel="stylesheet">

  <style>
    body {
      font-family: 'Lato', sans-serif;
      text-align: center;
      margin: 0;
      padding: 0;
      background-color: #f9f9f9;
      color: #333;
    }

    .back-link {
      position: absolute;
      top: 20px;
      left: 20px;
      padding: 10px 18px;
      font-size: 1em;
      font-weight: 600;
      background-color: #eee;
      border-radius: 6px;
      text-decoration: none;
      color: #333;
      box-shadow: 0 2px 6px rgba(0,0,0,0.15);
      transition: background 0.2s ease, color 0.2s ease;
    }

    .back-link:hover {
      background-color: #ddd;
      color: #000;
    }

    h1 {
      font-size: 3em;
      margin: 60px 0 40px;
      font-weight: 700;
      color: #222;
    }

    .section {
      margin: 10px auto;
      padding: 10px 5px;
      width: 90%;
      background: #fff;
      border-radius: 12px;
      box-shadow: 0 4px 12px rgba(0,0,0,0.1);
    }

    .section h3 {
      margin-bottom: 20px;
      font-size: 1.8em;
      font-weight: 600;
      color: #111;
    }

    .images {
      display: flex;
      justify-content: center;
      align-items: center;
      gap: 40px;
      margin-bottom: 20px;
    }

    img {
      max-width: 600px;
      max-height: 500px;
      border-radius: 10px;
      flex-shrink: 0;
      box-shadow: 0 3px 10px rgba(0,0,0,0.15);
      transition: transform 0.2s ease;
    }

    img:hover {
      transform: scale(1.05);
    }

    .description {
      font-size: 1.1em;
      line-height: 1.7;
      max-width: 1200px;
      margin: 30px auto;
      color: #555;
    }

    .big-img {
      max-width: 90%;
      height: auto;
      margin-top: 10px;
      margin-bottom: 10px;
    }
  </style>
</head>
<body>
  <a href="https://eldenyap48.github.io/" class="back-link">← Back</a>

  <h1>CS 180 Project 4: Neural Radiance Field!</h1>

  <div class="section">
    <h3>Part 0: Calibrating Your Camera and Capturing a 3D Scan</h3>
    <div class="description">
      First, I calculated camera intrinsics (K) and distortion coefficients. Next, I did a 3D object scan and calculated the camera poses for each of the images. Finally, I was able to undistort the image and create a dataset. Below are 2 screenshots of my cloud of cameras in Viser showing the camera frustums' poses and images.
    </div>
    <div class="images">
      <img src="media/viser0.png">
      <img src="media/viser1.png">
    </div>
  </div>

  <div class="section">
    <h3>Part 1: Fit a Neural Field to a 2D Image</h3>
    <div class="description">
      Our model is a coordinate-based neural field that maps 2D pixel coordinates to RGB values. It uses a positional encoding with 10 frequency bands, expanding each (x, y) input to a 42-dimensional vector. This encoded vector is passed through an MLP with three hidden layers, each with width 256 and ReLU activations, followed by a final linear layer and a sigmoid to produce RGB values in the range [0, 1]. The network is trained for 2000 iterations using the Adam optimizer with a learning rate of 1e-2, minimizing MSE over random batches of 10,000 pixels.
    </div>
    <div class="images">
      <img src="media/fox_training_progression.png" class="big-img">
    </div>
    <div class="images">
      <img src="media/mp_training_progression.png" class="big-img">
    </div>
    <div class="description">
      To study how model capacity affects reconstruction quality, we trained four versions of our neural field using two different positional encoding frequencies (1 and 4) and two network widths (16 and 64). We plotted the final reconstructions in a 2x2 grid. Lower max frequency and smaller hidden width significantly limit the model’s ability to represent fine details, producing blurry or overly smooth images, while higher frequencies and wider layers produce sharper, more accurate reconstructions.
    </div>
    <div class="images">
      <img src="media/fox_grid.png" class="big-img">
    </div>
    <div class="description">
        The PSNR curve for training on the machu picchu image is shown as follows
    </div>
    <div class="images">
      <img src="media/mp_psnr.png" class="big-img">
    </div>
  </div>

  <div class="section">
    <h3>Part 2: Fit a Neural Radiance Field from Multi-view Images</h3>
    <div class="description">
        I implemented the <code>warpImageNearestNeighbor(im,H)</code> and <code>warpImageBilinear(im,H)</code> using inverse warping. To test the code, I applied it to 2 images for rectification.
    </div>
    <div class="images">
        <img src="media/rectify_1.png" class="big-img">
    </div>
    <div class="images">
        <img src="media/rectify_2.png" class="big-img">
    </div>
    <div class="description">
        Nearest Neighbor is fast but produces blocky or jagged results. Bilinear interpolation yields a smoother and more realistic transition but is slower.
    </div>
  </div>

</body>
</html>
