<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>CS 180 Project 5 Part A: The Power of Diffusion Models!</title>
  <link href="https://fonts.googleapis.com/css2?family=Lato:wght@400;700&display=swap" rel="stylesheet">

  <style>
    body {
      font-family: 'Lato', sans-serif;
      text-align: center;
      margin: 0;
      padding: 0;
      background-color: #f9f9f9;
      color: #333;
    }

    .back-link {
      position: absolute;
      top: 20px;
      left: 20px;
      padding: 10px 18px;
      font-size: 1em;
      font-weight: 600;
      background-color: #eee;
      border-radius: 6px;
      text-decoration: none;
      color: #333;
      box-shadow: 0 2px 6px rgba(0,0,0,0.15);
      transition: background 0.2s ease, color 0.2s ease;
    }

    .back-link:hover {
      background-color: #ddd;
      color: #000;
    }

    h1 {
      font-size: 3em;
      margin: 60px 0 40px;
      font-weight: 700;
      color: #222;
    }

    .section {
      margin: 10px auto;
      padding: 10px 5px;
      width: 90%;
      background: #fff;
      border-radius: 12px;
      box-shadow: 0 4px 12px rgba(0,0,0,0.1);
    }

    .section h3 {
      margin-bottom: 20px;
      font-size: 1.8em;
      font-weight: 600;
      color: #111;
    }

    .images {
      display: flex;
      justify-content: center;
      align-items: center;
      gap: 40px;
      margin-bottom: 20px;
    }

    img {
      max-width: 600px;
      max-height: 500px;
      border-radius: 10px;
      flex-shrink: 0;
      box-shadow: 0 3px 10px rgba(0,0,0,0.15);
      transition: transform 0.2s ease;
    }

    img:hover {
      transform: scale(1.05);
    }

    .description {
      font-size: 1.1em;
      line-height: 1.7;
      max-width: 1200px;
      margin: 30px auto;
      color: #555;
    }

    .big-img {
      max-width: 90%;
      height: auto;
      margin-top: 10px;
      margin-bottom: 10px;
    }
  </style>
</head>
<body>
  <a href="https://eldenyap48.github.io/" class="back-link">← Back</a>

  <h1>CS 180 Project 5 Part A: The Power of Diffusion Models!</h1>

  <div class="section">
    <h3>Part 0: Setup</h3>
    <div class="description">
        I designed a diverse set of creative text prompts and generated their corresponding prompt embeddings for use with the DeepFloyd IF text-to-image diffusion model. To ensure reproducibility across all experiments, I fixed the seed to 380 and consistently used it throughout the project. The following images were generated with the number of inference steps set to 20.
    </div>
    <div class="images">
      <img src="media/prompts_20_steps.png" class="big-img">
    </div>
    <div class="description">
        The following images were generated with the number of inference steps set to 40.
    </div>
    <div class="images">
      <img src="media/prompts_40_steps.png" class="big-img">
    </div>
    <div class="description">
        The generated images closely matched the semantic content of the text prompts, with clearer structure and finer details emerging as the number of inference steps increased. When using a lower number of steps, the outputs were faster to generate but appeared noisier and less coherent, while higher step counts produced sharper, more visually consistent results that better reflected the intended prompts.
    </div>

  <div class="section">
    <h3>Part 1.1: Implementing the Forward Process</h3>
    <div class="description">
      I implemented the forward (noising) process of a diffusion model, which progressively corrupts a clean image by adding Gaussian noise over time. Using a resized image of the Berkeley Campanile, I applied increasing noise levels at timesteps 250, 500, and 750 to visualize how structure is gradually destroyed as the diffusion process progresses.
    </div>
    <div class="images">
      <img src="media/noisy_campanile.png" class="big-img">
    </div>
  </div>

  <div class="section">
    <h3>Part 1.2: Classical Denoising</h3>
    <div class="description">
      I applied classical Gaussian blur filtering to noisy versions of the Berkeley Campanile at timesteps 250, 500, and 750. The results show that while Gaussian blurring can reduce high-frequency noise at lower noise levels, it quickly fails to recover meaningful structure as noise increases, producing overly smooth and distorted images.
    </div>
    <div class="images">
      <img src="media/classical_denoisy.png" class="big-img">
    </div>
  </div>

  <div class="section">
    <h3>Part 1.3: One-Step Denoising</h3>
    <div class="description">
      Using a pretrained diffusion UNet from DeepFloyd IF, I performed one-step denoising on noisy versions of the Campanile at timesteps 250, 500, and 750. The model successfully predicted the noise present in each image and enabled partial reconstruction of the original signal in a single reverse step. While fine details remain degraded at higher noise levels, the results clearly demonstrate the model’s ability to recover meaningful structure far beyond what classical denoising methods can achieve.
    </div>
    <div class="images">
      <img src="media/one_step_denoise.png" class="big-img">
    </div>
  </div>

  <div class="section">
    <h3>Part 1.4: Iterative Denoising</h3>
    <div class="description">
      Using a strided diffusion schedule with an initial noise level of i_start = 10, I implemented the full iterative denoising process and visualized the progressive refinement of the Campanile image at regular intervals. The results clearly show how repeated diffusion steps gradually recover structure from heavy noise, producing a high-quality final reconstruction.
    </div>
    <div class="images">
      <img src="media/iterative_denoise_intermediates.png" class="big-img">
    </div>
    <div class="images">
      <img src="media/denoise_comparisons.png" class="big-img">
    </div>
    <div class="description">
      Both single-step denoising and Gaussian blur baselines perform significantly worse, highlighting the importance of multi-step diffusion for high-fidelity image restoration.
    </div>
  </div>

  <div class="section">
    <h3>Part 1.5: Diffusion Model Sampling</h3>
    <div class="description">
      By initializing the model with pure Gaussian noise and setting i_start = 0, I used the iterative diffusion process to generate images entirely from scratch. The model produces recognizable and semantically meaningful images from random noise, demonstrating the generative power of diffusion models.
    </div>
    <div class="images">
      <img src="media/diffusion_model_samples.png" class="big-img">
    </div>
  </div>

</body>
</html>
